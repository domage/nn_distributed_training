experiment:
  name: "dist_mnist_dsgt_dsgd_cadmm"
  data_dir: "../data/"
  output_metadir: "../results/"
  use_cuda: true
  writeout: true
  data_split_type: "hetero"
  loss: "NLL"
  graph:
    num_nodes: 5
    type: "wheel"
    p: 0.6
    gen_attempts: 10
  model:
    num_filters: 3
    kernel_size: 5
    linear_width: 64
  individual_training:
    train_solo: false
    optimizer: "adam"
    lr: 0.005
    epochs: 6
    train_batch_size: 100
    val_batch_size: 100
    verbose: true
problem_configs:
  problem1:
    problem_name: "dsgt"
    train_batch_size: 64
    val_batch_size: 128
    evaluate_frequency: 20
    verbose_evals: true
    metrics:
      - "forward_pass_count"
      - "validation_loss"
      - "consensus_error"
      - "top1_accuracy"
      - "current_epoch"
    optimizer_config:
      alg_name: "dsgt"
      alpha: 0.05
      outer_iterations: 750
      profile: false
  problem2:
    problem_name: "cadmm"
    train_batch_size: 64
    val_batch_size: 128
    evaluate_frequency: 20
    verbose_evals: true
    metrics:
      - "forward_pass_count"
      - "validation_loss"
      - "consensus_error"
      - "top1_accuracy"
      - "current_epoch"
    optimizer_config:
      alg_name: "cadmm"
      rho_init: 1.0
      rho_scaling: 1.0
      outer_iterations: 750
      primal_iterations: 3
      primal_optimizer: "adam"
      primal_lr: 0.005
      profile: false
  problem3:
    problem_name: "dsgd"
    train_batch_size: 64
    val_batch_size: 128
    evaluate_frequency: 20
    verbose_evals: true
    metrics:
      - "forward_pass_count"
      - "validation_loss"
      - "consensus_error"
      - "top1_accuracy"
      - "current_epoch"
    optimizer_config:
      alg_name: "dsgd"
      alpha0: 0.05
      mu: 0.01
      outer_iterations: 750
      profile: false