experiment:
  name: "dist_dense_tuning2"
  output_metadir: "../results/"
  writeout: true
  use_cuda: true
  data:
    data_dir: "../floorplans/32_data/"
    split_type: "trajectory"
    num_beams: 20
    beam_samps: 20
    scan_dist_scale: 0.2
    round_density: True
    num_scans: 5000
    num_validation_scans: 500 
  loss: "BCE"
  graph:
    num_nodes: 6
    type: "wheel"
    p: 0.6
    gen_attempts: 10
  model:
    shape: [2, 86, 32, 32, 32, 1]
    scale: 0.05
  individual_training:
    train_solo: True
    optimizer: "adam"
    lr: 0.005
    epochs: 6
    train_batch_size: 10000
    val_batch_size: 10000
    verbose: True
problem_configs:
  problem1:
    problem_name: "batchsize_2k"
    train_batch_size: 2000
    val_batch_size: 10000
    evaluate_frequency: 20
    verbose_evals: True
    metrics:
      - "forward_pass_count"
      - "validation_loss"
      - "consensus_error"
      - "mesh_grid_density"
      - "current_epoch"
    optimizer_config:
      alg_name: "cadmm"
      rho_init: 1.0
      rho_scaling: 1.0
      outer_iterations: 500
      primal_iterations: 5
      primal_optimizer: "adam"
      primal_lr: 0.01
  problem2:
    problem_name: "batchsize_6k"
    train_batch_size: 2000
    val_batch_size: 10000
    evaluate_frequency: 20
    verbose_evals: True
    metrics:
      - "forward_pass_count"
      - "validation_loss"
      - "consensus_error"
      - "mesh_grid_density"
      - "current_epoch"
    optimizer_config:
      alg_name: "cadmm"
      rho_init: 1.0
      rho_scaling: 1.0
      outer_iterations: 500
      primal_iterations: 10
      primal_optimizer: "adam"
      primal_lr: 0.01
  problem3:
    problem_name: "batchsize_12k"
    train_batch_size: 12000
    val_batch_size: 10000
    evaluate_frequency: 20
    verbose_evals: True
    metrics:
      - "forward_pass_count"
      - "validation_loss"
      - "consensus_error"
      - "mesh_grid_density"
      - "current_epoch"
    optimizer_config:
      alg_name: "cadmm"
      rho_init: 1.0
      rho_scaling: 1.0
      outer_iterations: 500
      primal_iterations: 10
      primal_optimizer: "adam"
      primal_lr: 0.01